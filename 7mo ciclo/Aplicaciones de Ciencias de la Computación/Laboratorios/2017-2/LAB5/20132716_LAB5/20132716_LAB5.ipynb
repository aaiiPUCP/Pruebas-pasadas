{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (8 points): Automated SMS spam filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data, look around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping the *real* first step (fleshing out specs, finding out what is it we want to be doing -- often highly non-trivial in practice!), let's download the dataset we'll be using in this demo. Go to https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection and download the zip file. Unzip it under `data` subdirectory. You should see a file called `SMSSpamCollection`, about 0.5MB in size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ ls -l data\n",
    "total 1352\n",
    "-rw-r--r--@ 1 kofola  staff  477907 Mar 15  2011 SMSSpamCollection\n",
    "-rw-r--r--@ 1 kofola  staff    5868 Apr 18  2011 readme\n",
    "-rw-r-----@ 1 kofola  staff  203415 Dec  1 15:30 smsspamcollection.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages** (see the `readme` file for more info):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [line.rstrip() for line in open('SMSSpamCollection.txt')]\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of texts is also sometimes called \"corpus\". Let's print the first ten messages in this SMS corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "for message_no, message in enumerate(messages[:10]):\n",
    "    print (message_no, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is a [TSV](http://en.wikipedia.org/wiki/Tab-separated_values) (\"tab separated values\") file, where the first column is a label saying whether the given message is a normal message (\"ham\") or \"spam\". The second column is the message itself.\n",
    "\n",
    "This corpus will be our labeled training set. Using these ham/spam examples, we'll **train a machine learning model to learn to discriminate between ham/spam automatically**. Then, with a trained model, we'll be able to **classify arbitrary unlabeled messages** as ham or spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://radimrehurek.com/data_science_python/plot_ML_flow_chart_11.png)](http://www.astroml.org/sklearn_tutorial/general_concepts.html#supervised-learning-model-fit-x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of parsing TSV (or CSV, or Excel...) files by hand, we can use Python's `pandas` library to do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      ham  Even my brother is not like to speak with me. ...\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     spam  WINNER!! As a valued network customer you have...\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...\n",
      "10     ham  I'm gonna be home soon and i don't want to tal...\n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "13     ham  I've been searching for the right words to tha...\n",
      "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
      "16     ham                         Oh k...i'm watching here:)\n",
      "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
      "18     ham  Fine if thats the way u feel. Thats the way ...\n",
      "19    spam  England v Macedonia - dont miss the goals/team...\n",
      "20     ham          Is that seriously how you spell his name?\n",
      "21     ham    I‘m going to try for 2 months ha ha only joking\n",
      "22     ham  So ü pay first lar... Then when is da stock co...\n",
      "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
      "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
      "25     ham  Just forced myself to eat a slice. I'm really ...\n",
      "26     ham                     Lol your always so convincing.\n",
      "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
      "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
      "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
      "...    ...                                                ...\n",
      "5544   ham           Armand says get your ass over to epsilon\n",
      "5545   ham             U still havent got urself a jacket ah?\n",
      "5546   ham  I'm taking derek &amp; taylor to walmart, if I...\n",
      "5547   ham      Hi its in durban are you still on this number\n",
      "5548   ham         Ic. There are a lotta childporn cars then.\n",
      "5549  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5550   ham                 No, I was trying it all weekend ;V\n",
      "5551   ham  You know, wot people wear. T shirts, jumpers, ...\n",
      "5552   ham        Cool, what time you think you can get here?\n",
      "5553   ham  Wen did you get so spiritual and deep. That's ...\n",
      "5554   ham  Have a safe trip to Nigeria. Wish you happines...\n",
      "5555   ham                        Hahaha..use your brain dear\n",
      "5556   ham  Well keep in mind I've only got enough gas for...\n",
      "5557   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5558   ham  Yes i have. So that's why u texted. Pshew...mi...\n",
      "5559   ham  No. I meant the calculation is the same. That ...\n",
      "5560   ham                             Sorry, I'll call later\n",
      "5561   ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5562   ham                  Anything lor. Juz both of us lor.\n",
      "5563   ham  Get me out of this dump heap. My mom decided t...\n",
      "5564   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5565   ham                                Ard 6 like dat lor.\n",
      "5566   ham  Why don't you wait 'til at least wednesday to ...\n",
      "5567   ham                                       Huh y lei...\n",
      "5568  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570   ham               Will ü b going to esplanade fr home?\n",
      "5571   ham  Pity, * was in mood for that. So...any other s...\n",
      "5572   ham  The guy did some bitching but I acted like i'd...\n",
      "5573   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "messages = pandas.read_csv('SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "print (messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `pandas`, we can also view aggregate statistics easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4827</td>\n",
       "      <td>4518</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4827   4518                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are the messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message  length\n",
      "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
      "1   ham                      Ok lar... Joking wif u oni...      29\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
      "3   ham  U dun say so early hor... U c already then say...      49\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      61\n"
     ]
    }
   ],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))\n",
    "print (messages.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82fc1af160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5574.000000\n",
       "mean       80.478292\n",
       "std        59.848302\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is that super long message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\"]\n"
     ]
    }
   ],
   "source": [
    "print (list(messages.message[messages.length > 900]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1085]\n"
     ]
    }
   ],
   "source": [
    "print (list(messages[messages.length > 900].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any difference in message length between spam and ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAEQCAYAAAAXjQrJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82f844b908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50, figsize=(12,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good fun, but how do we make computer understand the plain text messages themselves? Or can it under such malformed gibberish at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "Doing that requires essentially three steps, in the bag-of-words model:\n",
    "\n",
    "1. counting how many times does a word occur in each message (term frequency)\n",
    "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "3. normalizing the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector has as many dimensions as there are unique words in the SMS corpus.\n",
    "\n",
    "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "sms_tfidf = vectorizer.fit_transform(messages['message'].values)\n",
    "\n",
    "print(sms_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 (2 points): Analyze the new dataset and explain (a) its structure and (b) the meaning of the values.\n",
    "\n",
    "El nuevo dataset está estructurado en una matriz de correspondencia de una tupla (n,t) a un valor de f(n,t), \n",
    "en donde n es el número de mensajes en el dataset, t es el número asignado a alguna palabra, y f(n,t) es el TF-IDF \n",
    "calculado a partir de los valores de n y t.\n",
    "\n",
    "En el print sms_tfidf.shape nos sale los valores de 5574 y 8713. Esto significa que hay 5574 mensajes, en los cuales \n",
    "dentro de ellos hay 8713 palabras diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a model, detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With messages represented as vectors, we can finally train our spam/ham classifier. This part is pretty straightforward, and there are many libraries that realize the training algorithms.\n",
    "The library sklearn.naive_bayes includes implementations of three Naïve Bayes classifiers\n",
    "- GaussianNB\n",
    "- MultinomialNB \n",
    "- BernoulliNB\n",
    "\n",
    "#### Question 2 (1.5 points): We will use MultinomialNB, why? \n",
    "\n",
    "Porque el clasificador MultinomialNB es el más adecuado para valores discretos, como contar palabras de un documento. Aunque TF-IDF sea un valor continuo, este clasificador igual sigue siendo el más adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 (1.5 points): When are the other two NB versions used? \n",
    "\n",
    "Se utiliza el clasificador GaussianNB cuando podemos asumir que la distribución de probabilidad es normal. \n",
    "\n",
    "Se utiliza el clasificador BernoulliNB cuando trabajamos con valores booleanos como determinantes de nuestro algoritmo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "targets = messages['label'].values\n",
    "clf = classifier.fit(sms_tfidf, targets)\n",
    "\n",
    "classifier2 = MultinomialNB(0,True,None)\n",
    "clf2 = classifier2.fit(sms_tfidf, targets)\n",
    "\n",
    "classifier3 = MultinomialNB(1.0,False,None)\n",
    "clf3 = classifier3.fit(sms_tfidf, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying our single random message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "examples = ['Free travel, call only today!', 'Hello my friend']\n",
    "example_vector = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_vector)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! You can try it with your own texts, too.\n",
    "\n",
    "A natural question is to ask, how many messages do we classify correctly overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9761\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4827    0\n",
      "1   133  614\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.99      4827\n",
      "       spam       1.00      0.82      0.90       747\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5574\n",
      "\n",
      "Accuracy: 0.9998\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4827    0\n",
      "1     1  746\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00      4827\n",
      "       spam       1.00      1.00      1.00       747\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5574\n",
      "\n",
      "Accuracy: 0.9840\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4772   55\n",
      "1    34  713\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99      4827\n",
      "       spam       0.93      0.95      0.94       747\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "all_predictions = clf.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "\n",
    "all_predictions = clf2.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "\n",
    "all_predictions = clf3.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (1.5 points): By default, MultinomialNB uses the Additive Laplace smoothing. Change the classifier to work without smoothing. Explain new results comparing with the default version.\n",
    "\n",
    "The Additive Laplace smoothing sirve para no dividir entre 0 cuando se encuentra una nueva palabra. Al utilizarla, se suaviza los datos, perdiendo diferenciaciación entre ellos.\n",
    "\n",
    "El clasificador MultinomialNB sin usar the Additive Laplace smoothing resulta tener un accuracy mayor (0.9998) a comparación de cuando sí lo usa (0.9761). Esto es debido a que no estamos trabajando con un nuevo dataset para testear nuestra data. Es decir, solo estamos utilizando el mismo dataset original para entrenar al algoritmo, para testearlo.\n",
    "\n",
    "Esto quiere decir que no existirán nuevas palabras encontradas cuando exploremos nuestro test_dataset. Por lo tanto, no genera ninguna ganancia utilizando la suavización en este caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 (1.5 points): How are the prior probabilities computed when using default parameters? Change the classifier to work with uniform prior probabilities. Explain new results comparing with the default version.\n",
    "\n",
    "Cuando se usa parámetros por default, las probabilidades a priori son calculadas. Como se puede observar en la última ejecución, el classifier 3, las probabilidades a priori fueron uniformes para cada dato. A comparación del classifier 1, este aumenta su accuracy, esto es debido a que un cálculo a priori de las probabilidades de cada clase depende de nuestros datos que sigan algún tipo de distribución fija. Sin embargo, este no es el caso, por lo tanto, es mejor no utilizar las probabilidades a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (12 points): Automated mail spam detection\n",
    "\n",
    "* Repeat all previous steps, this time using a more complex corpus: mails dataset. Go to  http://www.aueb.gr/users/ion/data/enron-spam/ and download the Enron4 file, which is composed of two directories (ham and spam). You must to create the mail-class matrix in order to classify ham and spam mails, following the same steps of sms spam problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'join join'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"join\", \" join\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 (02 points): Load the corpus into a single pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "ham_folder = 'enron4/ham/'\n",
    "spam_folder = 'enron4/spam/'\n",
    "\n",
    "ham_files = [os.path.join(ham_folder, f) for f in os.listdir(ham_folder)]\n",
    "spam_files = [os.path.join(spam_folder, f) for f in os.listdir(spam_folder)]\n",
    "\n",
    "# Para abrir los files se necesita un encoding especial:\n",
    "#open(file, encoding='iso-8859-7')\n",
    "\n",
    "##Crear nuestro directorio gigante de mensajes con spam y con ham\n",
    "mensajes=[]\n",
    "for archivo in ham_files:\n",
    "    doc=[]\n",
    "    for linea in codecs.open(archivo, encoding='iso-8859-7'):\n",
    "        doc= doc + list(linea.rstrip())\n",
    "\n",
    "    doc= \"\".join(doc)\n",
    "    mensajes.append(doc)\n",
    "for archivo in spam_files:\n",
    "    doc=[]\n",
    "    for linea in codecs.open(archivo, encoding='iso-8859-7'):\n",
    "        doc= doc + list(linea.rstrip())\n",
    "\n",
    "    doc= \"\".join(doc)\n",
    "    mensajes.append(doc)\n",
    "    \n",
    "##Crear un arreglo dondo los 1500 primeros son ham y 4500 son spam\n",
    "labels=[]\n",
    "for _ in range(1500):\n",
    "    labels.append(\"ham\");\n",
    "for _ in range(4500):\n",
    "    labels.append(\"spam\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 (02 points): Vectorize the dataset: convert each message to a vector using a vectorizer like TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 95038)\n"
     ]
    }
   ],
   "source": [
    "#Datos a vectores\n",
    "vectorizer = TfidfVectorizer()\n",
    "sms_tfidf = vectorizer.fit_transform(mensajes)\n",
    "print(sms_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 3 (02 points): Split the dataset into train and test subdatasets randomly. Consider a test subdataset size of 30% of the original dataset size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (1.5 points): Train a MultinomialNB classifier with the train subdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "targets = labels\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "##targets = messages['label'].values\n",
    "clf = classifier.fit(sms_tfidf, targets)\n",
    "\n",
    "classifier2 = MultinomialNB(0,True,None)\n",
    "clf2 = classifier2.fit(sms_tfidf, targets)\n",
    "\n",
    "classifier3 = MultinomialNB(1.0,False,None)\n",
    "clf3 = classifier3.fit(sms_tfidf, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 (1.5 points): Test the performance of this classifier with the test subdataset. For each classifier, present a report similar to the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam']\n"
     ]
    }
   ],
   "source": [
    "examples = ['Estoy en laboratorio de aplica']\n",
    "example_vector = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_vector)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9243\n",
      "\n",
      "Confusion matrix:\n",
      "      0     1\n",
      "0  1068   432\n",
      "1    22  4478\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      0.71      0.82      1500\n",
      "       spam       0.91      1.00      0.95      4500\n",
      "\n",
      "avg / total       0.93      0.92      0.92      6000\n",
      "\n",
      "Accuracy: 0.9995\n",
      "\n",
      "Confusion matrix:\n",
      "      0     1\n",
      "0  1500     0\n",
      "1     3  4497\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00      1500\n",
      "       spam       1.00      1.00      1.00      4500\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6000\n",
      "\n",
      "Accuracy: 0.9403\n",
      "\n",
      "Confusion matrix:\n",
      "      0     1\n",
      "0  1187   313\n",
      "1    45  4455\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      0.79      0.87      1500\n",
      "       spam       0.93      0.99      0.96      4500\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "all_predictions = clf.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(labels, all_predictions)\n",
    "cm = confusion_matrix(labels, all_predictions)\n",
    "statistics = classification_report(labels, all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "\n",
    "all_predictions = clf2.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(labels, all_predictions)\n",
    "cm = confusion_matrix(labels, all_predictions)\n",
    "statistics = classification_report(labels, all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "\n",
    "all_predictions = clf3.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(labels, all_predictions)\n",
    "cm = confusion_matrix(labels, all_predictions)\n",
    "statistics = classification_report(labels, all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy: 0.9395\n",
    "\n",
    "Confusion matrix:\n",
    "       0       1\n",
    "0  14414    6305\n",
    "1   1078  100292\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        ham       0.93      0.70      0.80     20719\n",
    "       spam       0.94      0.99      0.96    101370\n",
    "\n",
    "avg / total       0.94      0.94      0.94    122089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 6 (03 points): Compare the performance of this classifier with at least three other classifiers, reporting the same information as the previous question. Are the Naive Bayes models the best-performing ones?\n",
    "\n",
    "\n",
    "El performance de este es mucho mejor que los 3 clasificadores anteriores, debido a que no utiliza el mismo data_set para entrenar y testear, y como se mencionó anteriormente, al utilizar un nuevo dataset, genera mayor ganancia.\n",
    "\n",
    "Una ventaja del Naive Bayes models es que solo requiere una pequeña cantidad de datos de entrenamiento para estimar los parámetros necesarios para la clasificación. Sin embargo, no siempre llega a estimar correctamente, ya que determina en ausencia de otras características que pueden ser importantes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
