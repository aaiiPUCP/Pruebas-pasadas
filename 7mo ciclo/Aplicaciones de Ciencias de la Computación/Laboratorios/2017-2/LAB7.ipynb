{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea de BackPropagation\n",
    "\n",
    "En el presente laboratorio Ud. debe diseñar una red neuronal con dos capas intermedias para el problema de reconocimiento de dígitos manuscritos. Analice y estudie el código de la solución con una sola capa intermedia (NNBackpropagation3capas.ipynb), \n",
    "Para ello debe codear las funciones de:\n",
    "1. Forward propagation (04 puntos)\n",
    "2. Función de costo (02 puntos)\n",
    "3. Back-propagation (08 puntos)\n",
    "4. Predicción (02 puntos)\n",
    "5. Qué parámetros hacen que Ud. encuentre el mejor resultado? (04 puntos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline\n",
    "\n",
    "data = loadmat('ex3data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10], dtype=uint8),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y_onehot[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 401), (30, 21), (10, 31))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = 400\n",
    "hidden_size1 = 20\n",
    "hidden_size2 = 30\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size1 * (input_size + 1) + hidden_size2 * (hidden_size1 + 1) + num_labels * (hidden_size2 + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = X.shape[0]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape, theta3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2, theta3):\n",
    "#Implemente código\n",
    "    m = X.shape[0]\n",
    "\n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "  \n",
    "    z2 = a1 * theta1.T\n",
    " \n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    \n",
    "    z3 = a2 * theta2.T\n",
    "    \n",
    "    a3 = np.insert(sigmoid(z3), 0, values=np.ones(m), axis=1)\n",
    "   \n",
    "    z4 = a3 * theta3.T\n",
    "   \n",
    "    h = sigmoid(z4)\n",
    "    \n",
    "    return a1, z2, a2, z3, a3, z4, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401),\n",
       " (5000, 20),\n",
       " (5000, 21),\n",
       " (5000, 30),\n",
       " (5000, 31),\n",
       " (5000, 10),\n",
       " (5000, 10))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, a3.shape, z4.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate):\n",
    "#implemente código    \n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "    theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
    "    \n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)) + np.sum(np.power(theta3[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9879689911048182"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate):\n",
    "#Implemente código\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "    theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
    "    \n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    delta3 = np.zeros(theta3.shape)\n",
    "    \n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)) + np.sum(np.power(theta3[:,1:], 2)))\n",
    "    \n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]\n",
    "        z2t = z2[t,:]  \n",
    "        a2t = a2[t,:]  \n",
    "        z3t = z3[t,:]      \n",
    "        a3t = a3[t,:]\n",
    "        z4t = z4[t,:]\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        d4t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z3t = np.insert(z3t, 0, values=np.ones(1))\n",
    "        d3t = np.multiply((theta3.T * d4t.T).T, sigmoid_gradient(z3t))\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))\n",
    "        d2t = np.multiply((theta2.T * d3t[:,1:].T).T, sigmoid_gradient(z2t))\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + (d3t[:,1:]).T * a2t\n",
    "        delta3 = delta3 + d4t.T * a3t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    delta3 = delta3 / m\n",
    "    \n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    delta3[:,1:] = delta3[:,1:] + (theta3[:,1:] * learning_rate) / m\n",
    "    \n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2), np.ravel(delta3)))\n",
    "    \n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.9879689911048182, (8960,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.31471072960888991\n",
       "     jac: array([  3.59518512e-04,  -4.70839047e-06,  -7.06293239e-07, ...,\n",
       "         6.62579329e-05,   1.79226446e-04,   3.61348910e-04])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 21\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.15438585, -0.02354195, -0.00353147, ..., -1.30000968,\n",
       "       -1.96038596, -0.03605886])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size1,hidden_size2, num_labels, X, y_onehot, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [10],\n",
       "       [10],\n",
       "       ..., \n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implemente predicción\n",
    "X = np.matrix(X)\n",
    "\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "theta3 = np.matrix(np.reshape(fmin.x[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 99.48%\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print ('accuracy = {0}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Qué parámetros hacen que Ud. encuentre el mejor resultado?\n",
    "\n",
    "#Para encontrar el mejor resultado, es mejor utilizar el valor más alto \n",
    "#y estable de learning rate. Además, que a menor número de hidden_size, \n",
    "#resulta ser más efectivo que números mayores, el cual tardaría mucho \n",
    "#en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Laboratorio de BackPropagation\n",
    "\n",
    "En el presente laboratorio Ud. debe usar la red neuronal desarrollada previamente en la tarea dejada en aula y desarrollar lo siguiente:\n",
    "1. Tarea BackPropagation 4 capas (10 puntos)\n",
    "2. Dividir la data en dos conjuntos (TrainSet y TestSet) (02 puntos)\n",
    "3. Entrene el algoritmos con el TrainSet (04 puntos)\n",
    "4. Realice la predicción con el TestSet (02 puntos)\n",
    "5. Optimice su? (04 puntos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar la data original del MNIST y dividirla en Conjunto de Entrenamiento (primeros 60000) y \n",
    "conjunto de Test (10000 restantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000,), (10000,))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implemente su código de separación aquí\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=mnist.data\n",
    "y=mnist.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=42)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 60000)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_onehot_train = encoder.fit_transform(y_train)\n",
    "y_onehot_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 785), (30, 21), (10, 31))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Su código de Entrenamiento aquí\n",
    "input_size = 784\n",
    "hidden_size1 = 20\n",
    "hidden_size2 = 30\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "\n",
    "params = (np.random.random(size=hidden_size1 * (input_size + 1) + hidden_size2 * (hidden_size1 + 1) + num_labels * (hidden_size2 + 1))) \n",
    "\n",
    "m = X_train.shape[0]\n",
    "X_train = np.matrix(X_train)\n",
    "y_train = np.matrix(y_train)\n",
    "\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape, theta3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(X_train, theta1, theta2, theta3):\n",
    "\n",
    "    m = X_train.shape[0]\n",
    "  \n",
    "    a1 = np.insert(X_train, 0, values=np.ones(m), axis=1)\n",
    "  \n",
    "    z2 = a1 * theta1.T\n",
    "\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "   \n",
    "    z3 = a2 * theta2.T\n",
    "\n",
    "    a3 = np.insert(sigmoid(z3), 0, values=np.ones(m), axis=1)\n",
    "\n",
    "    z4 = a3 * theta3.T\n",
    "\n",
    "    h = sigmoid(z4)\n",
    "    return a1, z2, a2, z3, a3, z4, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785),\n",
       " (60000, 20),\n",
       " (60000, 21),\n",
       " (60000, 30),\n",
       " (60000, 31),\n",
       " (60000, 10),\n",
       " (60000, 10))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, a3, z4, h = forward_propagate(X_train, theta1, theta2, theta3)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, a3.shape, z4.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate):\n",
    "#implemente código    \n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "    theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
    "    \n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)) + np.sum(np.power(theta3[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,60000) (1,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-bc6206111f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-152-f48c830479de>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0msecond_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_term\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msecond_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,60000) (1,10) "
     ]
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size1, hidden_size2, num_labels, X_train, y_onehot_train, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size1, hidden_size2, num_labels, X_train, y_train, learning_rate):\n",
    "#Implemente código\n",
    "    m = X_train.shape[0]\n",
    "    X = np.matrix(X_train)\n",
    "    y = np.matrix(y_train)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "    theta3 = np.matrix(np.reshape(params[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X_train, theta1, theta2, theta3)\n",
    "    \n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    delta3 = np.zeros(theta3.shape)\n",
    "    \n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)) + np.sum(np.power(theta3[:,1:], 2)))\n",
    "    \n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]\n",
    "        z2t = z2[t,:]  \n",
    "        a2t = a2[t,:]  \n",
    "        z3t = z3[t,:]      \n",
    "        a3t = a3[t,:]\n",
    "        z4t = z4[t,:]\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        d4t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z3t = np.insert(z3t, 0, values=np.ones(1))\n",
    "        d3t = np.multiply((theta3.T * d4t.T).T, sigmoid_gradient(z3t))\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))\n",
    "        d2t = np.multiply((theta2.T * d3t[:,1:].T).T, sigmoid_gradient(z2t))\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + (d3t[:,1:]).T * a2t\n",
    "        delta3 = delta3 + d4t.T * a3t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    delta3 = delta3 / m\n",
    "    \n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    delta3[:,1:] = delta3[:,1:] + (theta3[:,1:] * learning_rate) / m\n",
    "    \n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2), np.ravel(delta3)))\n",
    "    \n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,60000) (1,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-0d1868df1eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-e4b38eece8bd>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(params, input_size, hidden_size1, hidden_size2, num_labels, X_train, y_train, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0msecond_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_term\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msecond_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,60000) (1,10) "
     ]
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size1, hidden_size2, num_labels, X_train, y_onehot_train, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size1,hidden_size2, num_labels, X_train, y_onehot_train, learning_rate), method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Su código de predicción aqui\n",
    "X = np.matrix(X_test)\n",
    "\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1):hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1)], (hidden_size2, (hidden_size1 + 1))))\n",
    "theta3 = np.matrix(np.reshape(fmin.x[hidden_size1*(input_size+1)+hidden_size2*(hidden_size1+1):], (num_labels, (hidden_size2 + 1))))\n",
    "\n",
    "a1, z2, a2, z3, a3, z4, h = forward_propagate(X_test, theta1, theta2, theta3)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
