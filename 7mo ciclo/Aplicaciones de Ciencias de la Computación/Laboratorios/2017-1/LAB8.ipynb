{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Agente Conversacional (12 ptos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar, usando expresiones regulares, algunas reglas básicas que deberá utilizar un agente conversacional para responderle a un usuario real.\n",
    "<br> En los siguientes enunciados deberá satisfacer las preguntas (Q) con el tipo de respuesta indicada (A), además de probar su RE con la lista de queries indicada para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> P1.1. (1.5 puntos) <font face=\"Courier New\"> \n",
    "<br> Q: \"HELLO\", \"HELLOO\", \"HELLOOO\", ... \n",
    "<br> A: \"HELLO, I'M \\*\" </font></b>(coloquen el nombre que deseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: HELLO\n",
      "A: HELLO, I'M KARLA :D\n",
      "Q: HELLOO ARE YOU THERE?\n",
      "A: HELLO, I'M KARLA :D\n"
     ]
    }
   ],
   "source": [
    "#Completar y probar:\n",
    "queries1 = [\"HELLO\", \"HELLOO ARE YOU THERE?\"]\n",
    "\n",
    "for query in queries1:\n",
    "    m1 = re.search(r\"HELLO+\",query)   \n",
    "    if m1:\n",
    "        print \"Q:\",query\n",
    "        print \"A: HELLO, I'M KARLA :D\"\n",
    "        \n",
    "    #Implementar su RE e imprimir su rpta:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> P1.2. (1.5 puntos) <font face=\"Courier New\">\n",
    "<br> Q:  \"ARE YOU (A|AN) (COMPUTER|AI|A.I.|PROGRAM)?\" \n",
    "<br> A: \"THAT'S SO MEAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ARE YOU A COMPUTER?\n",
      "A:THAT'S SO MEAN\n",
      "Q: ARE YOU AN A.I.?\n",
      "A:THAT'S SO MEAN\n",
      "Q: ARE YOU AN AI?\n",
      "A:THAT'S SO MEAN\n",
      "Q: ARE YOU A PROGRAM?\n",
      "A:THAT'S SO MEAN\n"
     ]
    }
   ],
   "source": [
    "#Completar y probar:\n",
    "queries2 = [\"ARE YOU A COMPUTER?\", \"ARE YOU AN A.I.?\", \"ARE YOU AN AI?\", \"ARE YOU A PROGRAM?\", \"ARE YOU A STUDENT?\"]\n",
    "\n",
    "for query in queries2:\n",
    "    m1 = re.search(r\"ARE YOU (A|AN) (COMPUTER|AI|A\\.I\\.|PROGRAM)\\?\",query)\n",
    "    if m1:\n",
    "        print \"Q:\",query\n",
    "        print \"A:THAT'S SO MEAN\"\n",
    "    #Implementar su RE e imprimir su rpta:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> P1.3. (2.0 puntos) <font face=\"Courier New\">\n",
    "<br> Q:  \"(I AM|I'M) \\*ED\" \n",
    "<br> A: \"WHY ARE YOU FEELING \\*ED?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: I AM WORRIED\n",
      "A: WHY ARE YOU FEELING WORRIED?\n",
      "Q: I'M DISTURBED\n",
      "A: WHY ARE YOU FEELING DISTURBED?\n"
     ]
    }
   ],
   "source": [
    "#Completar y probar:\n",
    "queries3 = [\"I AM WORRIED\", \"I'M DISTURBED\"]\n",
    "\n",
    "for query in queries3:\n",
    "    m1 = re.search(r\"(I AM|I'M) (\\w+)\",query)\n",
    "    if m1:\n",
    "        print \"Q:\",query\n",
    "        print \"A: WHY ARE YOU FEELING \" + m1.group(2).upper() + '?'\n",
    "    #Implementar su RE e imprimir su rpta:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> P1.4. (2.0 puntos) <font face=\"Courier New\">\n",
    "<br> Q:  \"(I AM|I'M|HE IS|SHE IS|HE'S|SHE'S) \\*ED\" \n",
    "<br> A: \"WHY (ARE YOU|IS SHE|IS HE) FEELING \\*ED?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: HE IS CONCERNED\n",
      "A: WHY IS HE FEELING CONCERNED?\n",
      "Q: SHE'S PERTURBED\n",
      "A: WHY IS SHE FEELING PERTURBED?\n"
     ]
    }
   ],
   "source": [
    "#Completar y probar:\n",
    "queries4 = [\"HE IS CONCERNED\", \"SHE'S PERTURBED\"]\n",
    "ans=[\"ARE YOU\",\"IS SHE\",\"IS HE\"]\n",
    "for query in queries4:\n",
    "    m1 = re.search(r\"(I AM|I'M|HE IS|SHE IS|HE'S|SHE'S) (\\w+)\",query)\n",
    "    if m1:\n",
    "        print \"Q:\",query\n",
    "        expQ=m1.group(1).upper()\n",
    "        expA=\"\"\n",
    "        if(expQ==\"I AM\" or expQ==\"I'M\"):\n",
    "            expA=ans[0]\n",
    "        elif(expQ==\"SHE IS\" or expQ==\"SHE'S\"):\n",
    "            expA=ans[1]\n",
    "        else:\n",
    "            expA=ans[2]\n",
    "        print \"A: WHY \"+ expA +\" FEELING \" + m1.group(2).upper() + '?'\n",
    "    #Implementar su RE e imprimir su rpta:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> P1.5. (1.5 puntos) <font face=\"Courier New\">\n",
    "<br> Q: \"BYE\", \"BYEE\", ..., \"GOODBYE\", \"GOODBYEE\", ...\n",
    "<br> A: \"BYE! I HOPE TO TALK TO YOU AGAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: BYE\n",
      "A: BYE! I HOPE TO TALK TO YOU AGAIN\n",
      "Q: BYEEE, SEE YOU LATER\n",
      "A: BYE! I HOPE TO TALK TO YOU AGAIN\n",
      "Q: GOOD BYE\n",
      "A: BYE! I HOPE TO TALK TO YOU AGAIN\n",
      "Q: GOODBYE\n",
      "A: BYE! I HOPE TO TALK TO YOU AGAIN\n"
     ]
    }
   ],
   "source": [
    "#Completar y probar:\n",
    "queries5 = [\"BYE\", \"BYEEE, SEE YOU LATER\", \"GOOD BYE\",\"GOODBYE\"]\n",
    "\n",
    "for query in queries5:\n",
    "    m1 = re.search(r\"(GOOD)?((BYE)+)\",query)\n",
    "    if m1:\n",
    "        print \"Q:\",query\n",
    "        print \"A: BYE! I HOPE TO TALK TO YOU AGAIN\"\n",
    "    #Implementar su RE e imprimir su rpta:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P1.6. (3.5 puntos)\n",
    "<br>Implementar una función (ask_AGENT) que use todos los patrones indicados anteriormente y pueda responder a la conversación de dos usuarios.\n",
    "<br>OJO: </b>Debe considerar un caso adicional en el cual el 'query' no haga 'match' con ninguno de sus patrones (la respuesta del agente queda a su elección)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user1_talk = [\n",
    "    \"Hello\",\n",
    "    \"Are you a computer?\",\n",
    "    \"Sorry, I said that because I'm disturbed about something\",\n",
    "    \"I don't want to talk about it\",\n",
    "    \"I'm in a hurry, bye\"\n",
    "]\n",
    "user2_talk = [\n",
    "    \"Hi, are you an A.I.?\",\n",
    "    \"That was just a hunch\",\n",
    "    \"I just want to talk about a friend, he is worried\",\n",
    "    \"I don't know, things happen, I'm worried too\",\n",
    "    \"You are asking too much, it's time to say goodbye\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def ask_AGENT(q):\n",
    "    ### COMPLETAR ###\n",
    "    #asuman que el texto de 'query' ya está convertido a mayúsculas\n",
    "    m1 = re.search(r\"HELLO+\",q)\n",
    "    m2 = re.search(r\"ARE YOU (A|AN) (COMPUTER|AI|A\\.I\\.|PROGRAM)\\?\",q)\n",
    "    m3 = re.search(r\"(I AM|I'M) (\\w+)\",q)\n",
    "    m4 = re.search(r\"(I AM|I'M|HE IS|SHE IS|HE'S|SHE'S) (\\w+)\",q)\n",
    "    m5 = re.search(r\"(GOOD)?((BYE)+)\",q)\n",
    "    if m1:\n",
    "        query=\"HELLO, I'M KARLA :D\"       \n",
    "    elif m2:\n",
    "        query=\"THAT'S SO MEAN\"        \n",
    "    elif m3:\n",
    "        query=\"WHY ARE YOU FEELING \" + m3.group(2).upper() + '?'            \n",
    "    elif m4:\n",
    "        expQ=m4.group(1).upper()\n",
    "        expA=\"\"\n",
    "        if(expQ==\"I AM\" or expQ==\"I'M\"):\n",
    "            expA=ans[0]\n",
    "        elif(expQ==\"SHE IS\" or expQ==\"SHE'S\"):\n",
    "            expA=ans[1]\n",
    "        else:\n",
    "            expA=ans[2]\n",
    "        query=\"WHY \"+ expA +\" FEELING \" + m4.group(2).upper() + '?'        \n",
    "    elif m5:\n",
    "        query=\"BYE! I HOPE TO TALK TO YOU AGAIN\"\n",
    "    else:      \n",
    "        query=\"SORRY, I DIDN'T UNDERSTAND\"\n",
    "            \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Hello\n",
      "AGENT: HELLO, I'M KARLA :D\n",
      "USER: Are you a computer?\n",
      "AGENT: THAT'S SO MEAN\n",
      "USER: Sorry, I said that because I'm disturbed about something\n",
      "AGENT: WHY ARE YOU FEELING DISTURBED?\n",
      "USER: I don't want to talk about it\n",
      "AGENT: SORRY, I DIDN'T UNDERSTAND\n",
      "USER: I'm in a hurry, bye\n",
      "AGENT: WHY ARE YOU FEELING IN?\n"
     ]
    }
   ],
   "source": [
    "#Prueba 1:\n",
    "for q in user1_talk:\n",
    "    print \"USER:\", q\n",
    "    print \"AGENT:\", ask_AGENT(q.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Hi, are you an A.I.?\n",
      "AGENT: THAT'S SO MEAN\n",
      "USER: That was just a hunch\n",
      "AGENT: SORRY, I DIDN'T UNDERSTAND\n",
      "USER: I just want to talk about a friend, he is worried\n",
      "AGENT: WHY IS HE FEELING WORRIED?\n",
      "USER: I don't know, things happen, I'm worried too\n",
      "AGENT: WHY ARE YOU FEELING WORRIED?\n",
      "USER: You are asking too much, it's time to say goodbye\n",
      "AGENT: BYE! I HOPE TO TALK TO YOU AGAIN\n"
     ]
    }
   ],
   "source": [
    "#Prueba 2:\n",
    "for q in user2_talk:\n",
    "    print \"USER:\", q\n",
    "    print \"AGENT:\", ask_AGENT(q.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. 'Reviews' de Smartphones (8ptos)\n",
    "Se solicita pre-procesar una colección de documentos de comentarios/reviews sobre smartphones (específicamente el Xperia Z3 Compact). En la primera parte se está mostrando cómo se carga el dataset desde el archivo 'smartphones.csv' y se imprime la cantidad de comentarios que se han cargado, además de una muestra de uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>phone_id</th>\n",
       "      <th>phone_name</th>\n",
       "      <th>blank</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14317</td>\n",
       "      <td>141</td>\n",
       "      <td>Xperia Z3 Compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-20 22:52</td>\n",
       "      <td>BoFiS</td>\n",
       "      <td>The Z3 Compact is the single best, reasonably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14318</td>\n",
       "      <td>141</td>\n",
       "      <td>Xperia Z3 Compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-20 12:10</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Don't be affraid. You will know how durable th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14319</td>\n",
       "      <td>141</td>\n",
       "      <td>Xperia Z3 Compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-20 08:18</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Hi I need opinions. I have been thinking of ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14320</td>\n",
       "      <td>141</td>\n",
       "      <td>Xperia Z3 Compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-20 08:14</td>\n",
       "      <td>marCo</td>\n",
       "      <td>I got my z3c on The first day when it came to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14321</td>\n",
       "      <td>141</td>\n",
       "      <td>Xperia Z3 Compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-20 07:54</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Hi I need opinions. I have been thinking of ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  phone_id         phone_name  blank         timestamp  user_name  \\\n",
       "0  14317       141  Xperia Z3 Compact    NaN  2015-01-20 22:52      BoFiS   \n",
       "1  14318       141  Xperia Z3 Compact    NaN  2015-01-20 12:10        Tom   \n",
       "2  14319       141  Xperia Z3 Compact    NaN  2015-01-20 08:18  Anonymous   \n",
       "3  14320       141  Xperia Z3 Compact    NaN  2015-01-20 08:14      marCo   \n",
       "4  14321       141  Xperia Z3 Compact    NaN  2015-01-20 07:54  Anonymous   \n",
       "\n",
       "                                              review  \n",
       "0  The Z3 Compact is the single best, reasonably ...  \n",
       "1  Don't be affraid. You will know how durable th...  \n",
       "2  Hi I need opinions. I have been thinking of ge...  \n",
       "3  I got my z3c on The first day when it came to ...  \n",
       "4  Hi I need opinions. I have been thinking of ge...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('smartphones.csv', sep=';', header=None, index_col=False, names=['id', 'phone_id', 'phone_name', 'blank', 'timestamp', 'user_name', 'review'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Z3 Compact is the single best, reasonably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't be affraid. You will know how durable th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi I need opinions. I have been thinking of ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got my z3c on The first day when it came to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi I need opinions. I have been thinking of ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  The Z3 Compact is the single best, reasonably ...\n",
       "1  Don't be affraid. You will know how durable th...\n",
       "2  Hi I need opinions. I have been thinking of ge...\n",
       "3  I got my z3c on The first day when it came to ...\n",
       "4  Hi I need opinions. I have been thinking of ge..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[:6], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL REVIEWS: 180\n",
      "REVIEW[0]: The Z3 Compact is the single best, reasonably sized, smartphone to date. I have been watching all announcements and every other OEM makes lower-speced 'mini' devices that are not nearly as good as their larger counterparts. Sony packed in the same specs of their Z3 into an even better, smaller, package with the Z3 Compact. Look at GSM Arena's battery comparison chart and you'll see just how amazing it's battery life is.  Performance is amazing, the camera is fantastic, especially since there is a two-stage camera button to launch and take pictures with. The body fits perfectly in my hand and is even waterproof! Add in a MicroSD slot and very minimal skinning by Sony on the ROM and you have a winning phone.  It is even easy to unlock the bootloader, root, and use xposed framework on the stock Sony ROM, making this an immediately customizable, and stable phone from day one.\n"
     ]
    }
   ],
   "source": [
    "list_reviews = df['review'].tolist()\n",
    "list_reviews = [review.decode('utf-8') for review in list_reviews]\n",
    "print \"TOTAL REVIEWS:\", len(list_reviews)\n",
    "print \"REVIEW[0]:\", list_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def stats_tokens(list_tokens):\n",
    "    print \" num_tokens  =\\t\", len(list_tokens)\n",
    "    vocab = Counter(list_tokens)\n",
    "    print \"|vocabulary| =\\t\", len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P2.1. (3.0 puntos)\n",
    "<br>Se están generando diferentes listas de 'tokens' a partir de la lista de 'reviews'. \n",
    "<br>Para cada uno se hace un conteo del total de 'tokens' y el tamaño del vocabulario ('stats_tokens')\n",
    "<br>Explique, para cada caso del 2 al 4, el motivo de por qué se está reduciendo el vocabulario y/o el número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de tokens 1:\n",
      " num_tokens  =\t10474\n",
      "|vocabulary| =\t3035\n"
     ]
    }
   ],
   "source": [
    "list_tokens_1 = []\n",
    "for review in list_reviews:\n",
    "    tokens = review.split() #split_tokens (se divide el 'review' en tokens según los espacios en blanco)\n",
    "    list_tokens_1.extend(tokens) #se añade al listado para contabilizar\n",
    "\n",
    "print \"Lista de tokens 1:\"\n",
    "vocab_1 = stats_tokens(list_tokens_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de tokens 2:\n",
      " num_tokens  =\t10397\n",
      "|vocabulary| =\t2378\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(ur\"[^\\w\\d'\\s]+\",'',text)\n",
    "\n",
    "list_tokens_2 = []\n",
    "for review in list_reviews:\n",
    "    review_without_punct = remove_punctuation(review)\n",
    "    tokens = review_without_punct.split()\n",
    "    list_tokens_2.extend(tokens)\n",
    "\n",
    "print \"Lista de tokens 2:\"\n",
    "vocab_2 = stats_tokens(list_tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coloque aquí su explicación: En este caso se está eliminando todos los signos de puntuación, ya que estos no pertenecen\n",
    "#a las palabras en sí. Con esto tenemos los tokens y el vocabulario más preciso. En el primer caso consideraba como palabras\n",
    "#diferentes a \"hola\" y \"hola,\". ESto ya no sucede en el caso 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de tokens 3:\n",
      " num_tokens  =\t10397\n",
      "|vocabulary| =\t2075\n"
     ]
    }
   ],
   "source": [
    "list_tokens_3 = []\n",
    "for review in list_reviews:\n",
    "    review = review.lower()\n",
    "    review_without_punct = remove_punctuation(review)\n",
    "    tokens = review_without_punct.split()\n",
    "    list_tokens_3.extend(tokens)\n",
    "\n",
    "print \"Lista de tokens 3:\"\n",
    "vocab_3 = stats_tokens(list_tokens_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coloque aquí su explicación: EN este caso, todas las palabras de cada review primero se pasan a lower case y también se\n",
    "#eliminan los signos de puntuación. EN este caso se considera a \"hola\" y \"HOLA\" como una misma palabra (como debería ser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de tokens 4:\n",
      " num_tokens  =\t10397\n",
      "|vocabulary| =\t1730\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "list_tokens_4 = []\n",
    "for review in list_reviews:\n",
    "    review = review.lower()\n",
    "    review_without_punct = remove_punctuation(review)\n",
    "    tokens = review_without_punct.split()\n",
    "    tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    list_tokens_4.extend(tokens_stemmed)\n",
    "\n",
    "print \"Lista de tokens 4:\"\n",
    "vocab_4 = stats_tokens(list_tokens_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coloque aquí su explicación:\n",
    "#Ahora no solo están las palabras en minúscula y sin signos de puntuación sino que se la ha aplicado stemming para\n",
    "#obtener forma truncada común a todas las variables morfológicas de las palabras. Así, consideramos a \"gato\" y \"gatos\"\n",
    "#como una sola palabra ya que ambas pertenecen a una misma raíz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P2.2. (1.0 punto)\n",
    "<br>Modifique la función 'stats_tokens' para que imprima también los 5 tokens más comunes en un listado, con su respectivo contador.\n",
    "<br>Luego, pruebe su función sobre: 'list_tokens_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def stats_tokens(list_tokens):\n",
    "    #MODIFICAR\n",
    "    print \" num_tokens  =\\t\", len(list_tokens)\n",
    "    vocab = Counter(list_tokens)\n",
    "    print \"|vocabulary| =\\t\", len(vocab)\n",
    "    print vocab.most_common(5)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num_tokens  =\t10397\n",
      "|vocabulary| =\t2075\n",
      "[(u'the', 408), (u'and', 272), (u'it', 264), (u'i', 240), (u'is', 218)]\n"
     ]
    }
   ],
   "source": [
    "vocab_3 = stats_tokens(list_tokens_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P2.3.\n",
    "<br>En el siguiente código, se están pre-procesando los 'reviews' de manera similar a 'list_tokens_3', pero sin dividir los tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 180\n",
      "ORIGINAL: Bad experience! Sudden death issue. My Z3 Compact is totally dead after three weeks use. Already with Sony Service Center for the last ten days. Z3 Compact has know motherboard problem, but unfortunately Sony is not acknowledging it. My last Sony purchase! \n",
      "PRE-PROCESADO: bad experience sudden death issue my z3 compact is totally dead after three weeks use already with sony service center for the last ten days z3 compact has know motherboard problem but unfortunately sony is not acknowledging it my last sony purchase \n"
     ]
    }
   ],
   "source": [
    "list_reviews_preprocessed = [remove_punctuation(review.lower()) for review in list_reviews]\n",
    "\n",
    "print len(list_reviews), len(list_reviews_preprocessed)\n",
    "print \"ORIGINAL:\", list_reviews[7]\n",
    "print \"PRE-PROCESADO:\", list_reviews_preprocessed[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P2.3.A (3.0 puntos)\n",
    "<br>Implemente una función que calcule la métrica IDF de un término ('term') con respecto a una colección de documentos ('list_documents'), y a partir de eso, debe calcular el IDF de los 5 términos más comunes obtenidos en la pregunta P2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def IDF(term, list_documents):\n",
    "    num_documents = len(list_documents)\n",
    "    frecterm=0\n",
    "    for doc in list_documents:\n",
    "        if re.search(term,doc):\n",
    "            frecterm+=1\n",
    "    if frecterm==0:\n",
    "        frecterm1=1\n",
    "    ans=1.0*num_documents/frecterm\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num_tokens  =\t10397\n",
      "|vocabulary| =\t2075\n",
      "[(u'the', 408), (u'and', 272), (u'it', 264), (u'i', 240), (u'is', 218)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'the', u'and', u'it', u'i', u'is']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reemplace aquí los tokens identificados en P2.2\n",
    "vocab= stats_tokens(list_tokens_3)\n",
    "termaux = vocab.most_common(5)\n",
    "terms=[]\n",
    "for term in termaux:\n",
    "    terms.append(term[0])\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1.35338345865\n",
      "and 1.66666666667\n",
      "it 1.37404580153\n",
      "i 1.05263157895\n",
      "is 1.47540983607\n"
     ]
    }
   ],
   "source": [
    "#Para la prueba, se usará la lista de reviews pre-procesadas:\n",
    "for term in terms:\n",
    "    print term, IDF(term, list_reviews_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>P2.3.B (1.0 punto)\n",
    "<br>Calcule el IDF de estos otros términos y explique: \n",
    "<br>- ¿Por qué la diferencia de los valores con respecto a los 5 términos de la parte 'A'?, y \n",
    "<br>- ¿Cuáles serían mas relevantes en la colección de documentos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcd 60.0\n",
      "screen 3.82978723404\n"
     ]
    }
   ],
   "source": [
    "other_terms = ['lcd','screen']\n",
    "for term in other_terms:\n",
    "    print term, IDF(term, list_reviews_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Explique y responda:\n",
    "#la ocurrencia de lcd es menor en los documentos lo que nos da a entender que es relevante al momento de analizar,\n",
    "#a diferencia de las palabras más comunes como los conectores que suelen no tener importancia en un texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
